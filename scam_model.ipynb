{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxjEYGI3DpS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from scipy.sparse import hstack\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import joblib\n",
        "\n",
        "\n",
        "CSV_FILE = \"case_cu_pret_estim.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "needed_cols = [\"descriere\", \"data_cont\", \"nr_postari\", \"pret\", \"pret_estim\", \"scam\"]\n",
        "for c in needed_cols:\n",
        "    if c not in df.columns:\n",
        "        raise ValueError(f\"LipseÈ™te coloana '{c}' din {CSV_FILE}\")\n",
        "\n",
        "df[\"pret\"] = pd.to_numeric(df[\"pret\"], errors=\"coerce\")\n",
        "df[\"pret_estim\"] = pd.to_numeric(df[\"pret_estim\"], errors=\"coerce\")\n",
        "df[\"nr_postari\"] = pd.to_numeric(df[\"nr_postari\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "df[\"delta_pret\"] = df[\"pret\"] - df[\"pret_estim\"]\n",
        "\n",
        "df[\"data_cont_parsed\"] = pd.to_datetime(\n",
        "    df[\"data_cont\"], errors=\"coerce\", dayfirst=True\n",
        ")\n",
        "today = pd.Timestamp.today()\n",
        "df[\"vechime_zile\"] = (today - df[\"data_cont_parsed\"]).dt.days\n",
        "df[\"vechime_zile\"] = df[\"vechime_zile\"].fillna(df[\"vechime_zile\"].median())\n",
        "\n",
        "df = df.dropna(subset=[\"pret\", \"pret_estim\", \"delta_pret\"])\n",
        "\n",
        "y = df[\"scam\"].astype(int)\n",
        "descrieri = df[\"descriere\"].fillna(\"\")\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=3\n",
        ")\n",
        "X_text = vectorizer.fit_transform(descrieri)\n",
        "\n",
        "X_num = np.column_stack([\n",
        "    df[\"vechime_zile\"].values,\n",
        "    df[\"nr_postari\"].values,\n",
        "    df[\"delta_pret\"].values\n",
        "])\n",
        "\n",
        "X = hstack([X_text, X_num])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"ðŸŽ¯ Exemplare dupÄƒ oversampling:\")\n",
        "print(pd.Series(y_train_bal).value_counts())\n",
        "\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "\n",
        "clf.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "joblib.dump(clf, \"scam_model_logreg.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_descriere.pkl\")\n",
        "\n",
        "print(\"\\nâœ… Modelul Logistic Regression a fost salvat Ã®n 'scam_model_logreg.pkl'\")\n",
        "print(\"âœ… Vectorizatorul TF-IDF a fost salvat Ã®n 'tfidf_descriere.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXkrWbM-_GCB",
        "outputId": "5a323b09-1a81-4e47-ba56-1b27520c49a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Exemplare dupÄƒ oversampling:\n",
            "scam\n",
            "0    466\n",
            "1    466\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Accuracy: 1.0\n",
            "\n",
            "Confusion matrix:\n",
            " [[117   0]\n",
            " [  0   3]]\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       117\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00       120\n",
            "   macro avg       1.00      1.00      1.00       120\n",
            "weighted avg       1.00      1.00      1.00       120\n",
            "\n",
            "\n",
            "âœ… Modelul Logistic Regression a fost salvat Ã®n 'scam_model_logreg.pkl'\n",
            "âœ… Vectorizatorul TF-IDF a fost salvat Ã®n 'tfidf_descriere.pkl'\n"
          ]
        }
      ]
    }
  ]
}